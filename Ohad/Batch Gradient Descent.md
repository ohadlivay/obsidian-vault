unlike [[Gradient Descent]], we go through the entire dataset, calculate gradient. 


Pros
* Less oscillations and noisy steps toward minima
Cons
* slow to converge
* unfeasable for large datasets
* not able to be updated online